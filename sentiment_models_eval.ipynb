{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk \n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DistilBertForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been converted and saved as twitter-2016train-A.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_file = \"twitter-2016train-A.txt\"\n",
    "output_file = \"twitter-2016train-A.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, sep=\"\\t\", header=None, quoting=3)  \n",
    "\n",
    "data.columns = [\"ID\", \"Sentiment\", \"Text\"]\n",
    "\n",
    "# Save to CSV\n",
    "#data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"File has been converted and saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    3094\n",
       "neutral     2043\n",
       "negative     863\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('twitter-2016train-A.csv')\n",
    "data.head()\n",
    "data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5065"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def calculate_accuracy(dataset):\n",
    "    sia = SIA()\n",
    "    correct = 0\n",
    "    for index, row in dataset.iterrows():\n",
    "        text = row['Text']\n",
    "        true_label = row['Sentiment']\n",
    "\n",
    "        sentiment_scores = sia.polarity_scores(text)\n",
    "        predicted_label = 'positive' if sentiment_scores['compound'] > 0.05 else \\\n",
    "                          'negative' if sentiment_scores['compound'] < -0.05 else 'neutral'\n",
    "\n",
    "        if predicted_label == true_label:\n",
    "            correct += 1\n",
    "    \n",
    "    return correct / len(dataset)\n",
    "\n",
    "calculate_accuracy(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('Reddit_Data.csv')\n",
    "testdf = testdf.head(500)\n",
    "testdf.columns = [\"Text\", \"Sentiment\"]\n",
    "\n",
    "sentiment_mapping = {-1: \"negative\", 0: \"neutral\", 1: \"positive\"}\n",
    "testdf[\"Sentiment\"] = testdf[\"Sentiment\"].map(sentiment_mapping)\n",
    "\n",
    "testdf[\"Text\"] = testdf[\"Text\"].fillna(\"\").astype(str)\n",
    "\n",
    "testdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.51      0.45       391\n",
      "     neutral       0.46      0.34      0.39       765\n",
      "    positive       0.55      0.62      0.58       843\n",
      "\n",
      "    accuracy                           0.49      1999\n",
      "   macro avg       0.47      0.49      0.47      1999\n",
      "weighted avg       0.49      0.49      0.48      1999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "\n",
    "def calculate_classification_report(dataset):\n",
    "    sia = SIA()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        text = row['Text']\n",
    "        true_label = row['Sentiment']\n",
    "\n",
    "        sentiment_scores = sia.polarity_scores(text)\n",
    "        predicted_label = 'positive' if sentiment_scores['compound'] > 0.05 else \\\n",
    "                          'negative' if sentiment_scores['compound'] < -0.05 else 'neutral'\n",
    "\n",
    "        true_labels.append(true_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    report = classification_report(true_labels, predicted_labels, target_names=['negative', 'neutral', 'positive'])\n",
    "    print(report)\n",
    "    \n",
    "\n",
    "calculate_classification_report(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   neagative       0.28      0.31      0.30       391\n",
      "     neutral       0.43      0.39      0.41       765\n",
      "     positve       0.52      0.54      0.53       843\n",
      "\n",
      "    accuracy                           0.44      1999\n",
      "   macro avg       0.41      0.41      0.41      1999\n",
      "weighted avg       0.44      0.44      0.44      1999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_classification_report(dataset):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        text = row['Text']\n",
    "        true_label = row['Sentiment']\n",
    "\n",
    "        blob = TextBlob(text)\n",
    "        polarity = blob.sentiment.polarity\n",
    "\n",
    "        if polarity > 0:\n",
    "            predicted_label = 'positive'\n",
    "        elif polarity < 0:\n",
    "            predicted_label = 'negative'\n",
    "        else:\n",
    "            predicted_label = 'neutral'\n",
    "\n",
    "        true_labels.append(true_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    report = classification_report(true_labels, predicted_labels, target_names=['neagative', 'neutral', 'positve'], zero_division=0)\n",
    "    print(report)\n",
    "\n",
    "calculate_classification_report(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distilbert-base-uncased-finetuned-sst-2-english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.26      0.87      0.40       391\n",
      "     neutral       0.00      0.00      0.00       765\n",
      "    positive       0.66      0.54      0.60       843\n",
      "\n",
      "    accuracy                           0.40      1999\n",
      "   macro avg       0.31      0.47      0.33      1999\n",
      "weighted avg       0.33      0.40      0.33      1999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "def calculate_classification_report(dataset):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        text = row['Text']\n",
    "        true_label = row['Sentiment']\n",
    "        sentiment_prediction = classifier(text)[0]\n",
    "        predicted_label = sentiment_prediction['label'].lower() \n",
    "\n",
    "        if predicted_label == 'negative': \n",
    "            predicted_label = 'negative'\n",
    "        elif predicted_label == 'positive':\n",
    "            predicted_label = 'positive'\n",
    "        else:\n",
    "            predicted_label = 'neutral'  \n",
    "\n",
    "        true_labels.append(true_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    report = classification_report(true_labels, predicted_labels, target_names=['negative', 'neutral', 'positive'], zero_division=0)\n",
    "    print(report)\n",
    "\n",
    "calculate_classification_report(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# twitter-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 46\u001b[0m\n\u001b[0;32m     42\u001b[0m     report \u001b[38;5;241m=\u001b[39m classification_report(true_labels, predicted_labels, target_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m], zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(report)\n\u001b[1;32m---> 46\u001b[0m calculate_classification_report(data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def calculate_classification_report(dataset):\n",
    "    MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    for index, row in dataset.iterrows():\n",
    "        text = row['Text']\n",
    "        true_label = row['Sentiment']\n",
    "\n",
    "        text = preprocess(text)\n",
    "\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "\n",
    "        ranking = np.argsort(scores)\n",
    "        ranking = ranking[::-1]\n",
    "        predicted_label = 'positive' if ranking[0] == 2 else 'negative' if ranking[0] == 0 else 'neutral'\n",
    "\n",
    "        true_labels.append(true_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    report = classification_report(true_labels, predicted_labels, target_names=['negative', 'neutral', 'positive'], zero_division=0)\n",
    "    print(report)\n",
    "\n",
    "\n",
    "calculate_classification_report(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# twitter-roberta-base-sentiment-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.62      0.75      0.68       391\n",
      "     neutral       0.58      0.69      0.63       765\n",
      "     postive       0.85      0.63      0.72       843\n",
      "\n",
      "    accuracy                           0.67      1999\n",
      "   macro avg       0.69      0.69      0.68      1999\n",
      "weighted avg       0.70      0.67      0.68      1999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def calculate_classification_report(dataset):\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    config = AutoConfig.from_pretrained(MODEL)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        text = row['Text']\n",
    "        true_label = row['Sentiment']\n",
    "\n",
    "        text = preprocess(text)\n",
    "\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "\n",
    "        ranking = np.argsort(scores)\n",
    "        ranking = ranking[::-1]\n",
    "        predicted_label = config.id2label[ranking[0]]  \n",
    "\n",
    "        if predicted_label == 'positive':\n",
    "            predicted_label = 'positive'\n",
    "        elif predicted_label == 'negative':\n",
    "            predicted_label = 'negative'\n",
    "        else:\n",
    "            predicted_label = 'neutral'\n",
    "\n",
    "        true_labels.append(true_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    report = classification_report(true_labels, predicted_labels, target_names=['negative', 'neutral', 'postive'], zero_division=0)\n",
    "    print(report)\n",
    "\n",
    "\n",
    "calculate_classification_report(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Model\": [\"NLTK\", \"TextBlob\", \"Roberta (58M)\", \"Roberta (124M)\"],\n",
    "    \"Accuracy\": [0.48, 0.44, 0.74, 0.67],\n",
    "    \"Recall\": [0.49, 0.41, 0.75, 0.69],\n",
    "    \"F1-Score\": [0.47, 0.41, 0.74, 0.68],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df_melted = df.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "pivot_df = df_melted.pivot(index=\"Model\", columns=\"Metric\", values=\"Score\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "heatmap = sns.heatmap(\n",
    "    pivot_df,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    fmt=\".2f\",\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"label\": \"Score\"},\n",
    ")\n",
    "\n",
    "plt.title(\"Model Performance Metrics\", fontsize=16)\n",
    "plt.ylabel(\"Model\", fontsize=12)\n",
    "plt.xlabel(\"Metric\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "c:\\Users\\muham\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_15248\\2428271883.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at: Thu Dec  5 07:33:48 2024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e711efa7dd9b4ba8a3a2a50f6bf546f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6495, 'grad_norm': 6.784781455993652, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 0.634, 'grad_norm': 11.83465576171875, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.07}\n",
      "{'loss': 0.5725, 'grad_norm': 13.066274642944336, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 0.5455, 'grad_norm': 7.430876731872559, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 0.62, 'grad_norm': 7.372413158416748, 'learning_rate': 5e-06, 'epoch': 0.17}\n",
      "{'loss': 0.5535, 'grad_norm': 11.339559555053711, 'learning_rate': 6e-06, 'epoch': 0.2}\n",
      "{'loss': 0.5296, 'grad_norm': 18.505552291870117, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.23}\n",
      "{'loss': 0.5131, 'grad_norm': 15.720605850219727, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.27}\n",
      "{'loss': 0.5514, 'grad_norm': 10.298125267028809, 'learning_rate': 9e-06, 'epoch': 0.3}\n",
      "{'loss': 0.5404, 'grad_norm': 18.28573989868164, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 0.4385, 'grad_norm': 10.277826309204102, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.37}\n",
      "{'loss': 0.5043, 'grad_norm': 12.703731536865234, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n",
      "{'loss': 0.544, 'grad_norm': 22.293481826782227, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.43}\n",
      "{'loss': 0.535, 'grad_norm': 11.29834270477295, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.47}\n",
      "{'loss': 0.4202, 'grad_norm': 12.472315788269043, 'learning_rate': 1.5e-05, 'epoch': 0.5}\n",
      "{'loss': 0.6827, 'grad_norm': 9.22508716583252, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.53}\n",
      "{'loss': 0.6219, 'grad_norm': 10.210143089294434, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.57}\n",
      "{'loss': 0.5512, 'grad_norm': 11.29444408416748, 'learning_rate': 1.8e-05, 'epoch': 0.6}\n",
      "{'loss': 0.5702, 'grad_norm': 9.519049644470215, 'learning_rate': 1.9e-05, 'epoch': 0.63}\n",
      "{'loss': 0.5449, 'grad_norm': 21.402206420898438, 'learning_rate': 2e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6002, 'grad_norm': 19.707046508789062, 'learning_rate': 2.1e-05, 'epoch': 0.7}\n",
      "{'loss': 0.686, 'grad_norm': 9.309048652648926, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.73}\n",
      "{'loss': 0.5433, 'grad_norm': 10.00048828125, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.77}\n",
      "{'loss': 0.5259, 'grad_norm': 13.885879516601562, 'learning_rate': 2.4e-05, 'epoch': 0.8}\n",
      "{'loss': 0.5002, 'grad_norm': 13.459959030151367, 'learning_rate': 2.5e-05, 'epoch': 0.83}\n",
      "{'loss': 0.4863, 'grad_norm': 10.4888277053833, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.87}\n",
      "{'loss': 0.6131, 'grad_norm': 10.175925254821777, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.9}\n",
      "{'loss': 0.624, 'grad_norm': 15.532537460327148, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.93}\n",
      "{'loss': 0.5451, 'grad_norm': 8.470711708068848, 'learning_rate': 2.9e-05, 'epoch': 0.97}\n",
      "{'loss': 0.7121, 'grad_norm': 12.14891242980957, 'learning_rate': 3e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c00c877a2846ba968e0ab459097b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5294369459152222, 'eval_runtime': 65.7169, 'eval_samples_per_second': 18.26, 'eval_steps_per_second': 0.289, 'epoch': 1.0}\n",
      "{'loss': 0.445, 'grad_norm': 12.2139892578125, 'learning_rate': 3.1e-05, 'epoch': 1.03}\n",
      "{'loss': 0.4654, 'grad_norm': 25.845762252807617, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.07}\n",
      "{'loss': 0.4453, 'grad_norm': 18.3277530670166, 'learning_rate': 3.3e-05, 'epoch': 1.1}\n",
      "{'loss': 0.4632, 'grad_norm': 22.22279167175293, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.13}\n",
      "{'loss': 0.4648, 'grad_norm': 20.698711395263672, 'learning_rate': 3.5e-05, 'epoch': 1.17}\n",
      "{'loss': 0.5635, 'grad_norm': 20.40741729736328, 'learning_rate': 3.6e-05, 'epoch': 1.2}\n",
      "{'loss': 0.3939, 'grad_norm': 11.87649154663086, 'learning_rate': 3.7e-05, 'epoch': 1.23}\n",
      "{'loss': 0.4427, 'grad_norm': 21.463041305541992, 'learning_rate': 3.8e-05, 'epoch': 1.27}\n",
      "{'loss': 0.4069, 'grad_norm': 23.146318435668945, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.3}\n",
      "{'loss': 0.4573, 'grad_norm': 21.453569412231445, 'learning_rate': 4e-05, 'epoch': 1.33}\n",
      "{'loss': 0.4772, 'grad_norm': 9.42351245880127, 'learning_rate': 4.1e-05, 'epoch': 1.37}\n",
      "{'loss': 0.5569, 'grad_norm': 35.62211990356445, 'learning_rate': 4.2e-05, 'epoch': 1.4}\n",
      "{'loss': 0.4091, 'grad_norm': 10.756738662719727, 'learning_rate': 4.3e-05, 'epoch': 1.43}\n",
      "{'loss': 0.5575, 'grad_norm': 20.65028190612793, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.47}\n",
      "{'loss': 0.4962, 'grad_norm': 16.187854766845703, 'learning_rate': 4.5e-05, 'epoch': 1.5}\n",
      "{'loss': 0.4685, 'grad_norm': 37.46772384643555, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.53}\n",
      "{'loss': 0.3923, 'grad_norm': 13.804694175720215, 'learning_rate': 4.7e-05, 'epoch': 1.57}\n",
      "{'loss': 0.4677, 'grad_norm': 10.681010246276855, 'learning_rate': 4.8e-05, 'epoch': 1.6}\n",
      "{'loss': 0.6728, 'grad_norm': 7.243237495422363, 'learning_rate': 4.9e-05, 'epoch': 1.63}\n",
      "{'loss': 0.5482, 'grad_norm': 9.71860122680664, 'learning_rate': 5e-05, 'epoch': 1.67}\n",
      "{'loss': 0.5339, 'grad_norm': 20.645309448242188, 'learning_rate': 4.875e-05, 'epoch': 1.7}\n",
      "{'loss': 0.4781, 'grad_norm': 12.62758731842041, 'learning_rate': 4.75e-05, 'epoch': 1.73}\n",
      "{'loss': 0.4822, 'grad_norm': 8.605855941772461, 'learning_rate': 4.6250000000000006e-05, 'epoch': 1.77}\n",
      "{'loss': 0.635, 'grad_norm': 20.567237854003906, 'learning_rate': 4.5e-05, 'epoch': 1.8}\n",
      "{'loss': 0.5342, 'grad_norm': 13.458708763122559, 'learning_rate': 4.375e-05, 'epoch': 1.83}\n",
      "{'loss': 0.6139, 'grad_norm': 20.754491806030273, 'learning_rate': 4.25e-05, 'epoch': 1.87}\n",
      "{'loss': 0.5484, 'grad_norm': 16.246334075927734, 'learning_rate': 4.125e-05, 'epoch': 1.9}\n",
      "{'loss': 0.4643, 'grad_norm': 9.040209770202637, 'learning_rate': 4e-05, 'epoch': 1.93}\n",
      "{'loss': 0.5453, 'grad_norm': 15.703082084655762, 'learning_rate': 3.875e-05, 'epoch': 1.97}\n",
      "{'loss': 0.4923, 'grad_norm': 9.904703140258789, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78cfd754fef4815bc7717b7649773f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6037917733192444, 'eval_runtime': 65.0387, 'eval_samples_per_second': 18.451, 'eval_steps_per_second': 0.292, 'epoch': 2.0}\n",
      "{'loss': 0.2843, 'grad_norm': 10.6403169631958, 'learning_rate': 3.625e-05, 'epoch': 2.03}\n",
      "{'loss': 0.3025, 'grad_norm': 12.859021186828613, 'learning_rate': 3.5e-05, 'epoch': 2.07}\n",
      "{'loss': 0.2402, 'grad_norm': 10.841034889221191, 'learning_rate': 3.375000000000001e-05, 'epoch': 2.1}\n",
      "{'loss': 0.2027, 'grad_norm': 17.02640724182129, 'learning_rate': 3.2500000000000004e-05, 'epoch': 2.13}\n",
      "{'loss': 0.2991, 'grad_norm': 6.704336643218994, 'learning_rate': 3.125e-05, 'epoch': 2.17}\n",
      "{'loss': 0.23, 'grad_norm': 13.587874412536621, 'learning_rate': 3e-05, 'epoch': 2.2}\n",
      "{'loss': 0.2638, 'grad_norm': 11.648451805114746, 'learning_rate': 2.8749999999999997e-05, 'epoch': 2.23}\n",
      "{'loss': 0.3658, 'grad_norm': 18.21412467956543, 'learning_rate': 2.7500000000000004e-05, 'epoch': 2.27}\n",
      "{'loss': 0.2988, 'grad_norm': 6.200451850891113, 'learning_rate': 2.625e-05, 'epoch': 2.3}\n",
      "{'loss': 0.3355, 'grad_norm': 30.55249786376953, 'learning_rate': 2.5e-05, 'epoch': 2.33}\n",
      "{'loss': 0.4199, 'grad_norm': 17.574411392211914, 'learning_rate': 2.375e-05, 'epoch': 2.37}\n",
      "{'loss': 0.2388, 'grad_norm': 9.71192455291748, 'learning_rate': 2.25e-05, 'epoch': 2.4}\n",
      "{'loss': 0.2857, 'grad_norm': 20.25449562072754, 'learning_rate': 2.125e-05, 'epoch': 2.43}\n",
      "{'loss': 0.2643, 'grad_norm': 18.68423080444336, 'learning_rate': 2e-05, 'epoch': 2.47}\n",
      "{'loss': 0.2772, 'grad_norm': 25.29425048828125, 'learning_rate': 1.8750000000000002e-05, 'epoch': 2.5}\n",
      "{'loss': 0.213, 'grad_norm': 14.484719276428223, 'learning_rate': 1.75e-05, 'epoch': 2.53}\n",
      "{'loss': 0.2215, 'grad_norm': 12.057324409484863, 'learning_rate': 1.6250000000000002e-05, 'epoch': 2.57}\n",
      "{'loss': 0.2077, 'grad_norm': 17.474390029907227, 'learning_rate': 1.5e-05, 'epoch': 2.6}\n",
      "{'loss': 0.3057, 'grad_norm': 15.272207260131836, 'learning_rate': 1.3750000000000002e-05, 'epoch': 2.63}\n",
      "{'loss': 0.3144, 'grad_norm': 11.949554443359375, 'learning_rate': 1.25e-05, 'epoch': 2.67}\n",
      "{'loss': 0.2004, 'grad_norm': 6.441886901855469, 'learning_rate': 1.125e-05, 'epoch': 2.7}\n",
      "{'loss': 0.3327, 'grad_norm': 17.93321990966797, 'learning_rate': 1e-05, 'epoch': 2.73}\n",
      "{'loss': 0.1834, 'grad_norm': 10.335644721984863, 'learning_rate': 8.75e-06, 'epoch': 2.77}\n",
      "{'loss': 0.224, 'grad_norm': 3.8553051948547363, 'learning_rate': 7.5e-06, 'epoch': 2.8}\n",
      "{'loss': 0.3326, 'grad_norm': 15.389331817626953, 'learning_rate': 6.25e-06, 'epoch': 2.83}\n",
      "{'loss': 0.2795, 'grad_norm': 21.618301391601562, 'learning_rate': 5e-06, 'epoch': 2.87}\n",
      "{'loss': 0.2804, 'grad_norm': 27.983169555664062, 'learning_rate': 3.75e-06, 'epoch': 2.9}\n",
      "{'loss': 0.277, 'grad_norm': 19.925891876220703, 'learning_rate': 2.5e-06, 'epoch': 2.93}\n",
      "{'loss': 0.2482, 'grad_norm': 12.215250015258789, 'learning_rate': 1.25e-06, 'epoch': 2.97}\n",
      "{'loss': 0.2476, 'grad_norm': 27.012163162231445, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0750c30e78064997b41b35ace684667b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6798734664916992, 'eval_runtime': 62.986, 'eval_samples_per_second': 19.052, 'eval_steps_per_second': 0.302, 'epoch': 3.0}\n",
      "{'train_runtime': 3534.7372, 'train_samples_per_second': 4.074, 'train_steps_per_second': 0.255, 'train_loss': 0.44507627103063796, 'epoch': 3.0}\n",
      "Finished training at: Thu Dec  5 08:32:43 2024\n",
      "Training duration: 3535.0471205711365 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import time\n",
    "\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "def read_twitter_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    texts = data['Text'].tolist()\n",
    "    label_mapping = {\n",
    "        \"negative\": 0,\n",
    "        \"neutral\": 1,\n",
    "        \"positive\": 2\n",
    "    }\n",
    "    labels = data['Sentiment'].map(label_mapping).tolist()\n",
    "    return texts, labels\n",
    "\n",
    "train_file = \"twitter-2016train-A.csv\"\n",
    "test_file = \"twitter-2016dev-A.csv\"\n",
    "\n",
    "train_texts, train_labels = read_twitter_data(train_file)\n",
    "test_texts, test_labels = read_twitter_data(test_file)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "class TwitterSentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TwitterSentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = TwitterSentimentDataset(val_encodings, val_labels)\n",
    "test_dataset = TwitterSentimentDataset(test_encodings, test_labels)\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\", num_labels=3)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "print(f\"Starting training at: {time.ctime(start_time)}\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Finished training at: {time.ctime(end_time)}\")\n",
    "print(f\"Training duration: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.89      0.91       863\n",
      "     neutral       0.90      0.89      0.90      2043\n",
      "    positive       0.95      0.96      0.95      3094\n",
      "\n",
      "    accuracy                           0.93      6000\n",
      "   macro avg       0.92      0.91      0.92      6000\n",
      "weighted avg       0.93      0.93      0.93      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def calculate_classification_report(dataset):\n",
    "   \n",
    "    model_path = \"./results/checkpoint-900\"  \n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        text = row['Text']\n",
    "        true_label = row['Sentiment']\n",
    "\n",
    "        text = preprocess(text)\n",
    "\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "\n",
    "        ranking = np.argsort(scores)\n",
    "        ranking = ranking[::-1]\n",
    "        predicted_label = 'positive' if ranking[0] == 2 else 'negative' if ranking[0] == 0 else 'neutral'\n",
    "\n",
    "        true_labels.append(true_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "    report = classification_report(true_labels, predicted_labels, target_names=['negative', 'neutral', 'positive'], zero_division=0)\n",
    "    print(report)\n",
    "\n",
    "\n",
    "calculate_classification_report(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
