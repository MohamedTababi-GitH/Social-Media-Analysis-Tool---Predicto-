{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918a333f-46bc-4eac-8e92-246c09a2a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the platform for this CSV file:\n",
      "1: reddit\n",
      "2: bluesky\n",
      "3: twitter\n",
      "4: youtube\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "\n",
    "\n",
    "def get_ssh_db_connection(ssh_config):\n",
    "    \"\"\"\n",
    "    Establish an SSH tunnel and connect to MySQL database through SQLAlchemy.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tunnel = SSHTunnelForwarder(\n",
    "            (ssh_config['ssh_host'], 22),\n",
    "            ssh_username=ssh_config['ssh_user'],\n",
    "            ssh_password=ssh_config['ssh_password'],\n",
    "            remote_bind_address=(ssh_config['remote_host'], ssh_config['remote_port'])\n",
    "        )\n",
    "        tunnel.start()\n",
    "\n",
    "        engine = create_engine(\n",
    "            f\"mysql+pymysql://{ssh_config['mysql_user']}:{ssh_config['mysql_password']}@127.0.0.1:{tunnel.local_bind_port}/{ssh_config['mysql_db']}\"\n",
    "        )\n",
    "\n",
    "        return tunnel, engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error establishing SSH tunnel or database connection: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def clean_and_validate_timestamps(df):\n",
    "    \"\"\"\n",
    "    Clean and validate the Timestamp column in the DataFrame.\n",
    "    Replace invalid or missing timestamps with the current datetime.\n",
    "    \"\"\"\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "    df['Timestamp'].fillna(pd.Timestamp.now(), inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_or_create_platform_id(connection, platform_name):\n",
    "    \"\"\"\n",
    "    Retrieve the PlatformID for a platform name. Insert it if it doesn't exist.\n",
    "    \"\"\"\n",
    "    platform_query = text(\"SELECT PlatformID FROM Platform WHERE PlatformName = :platform_name\")\n",
    "    platform_result = connection.execute(platform_query, {\"platform_name\": platform_name}).fetchone()\n",
    "\n",
    "    if platform_result is None:\n",
    "        insert_platform_query = text(\"INSERT INTO Platform (PlatformName) VALUES (:platform_name)\")\n",
    "        connection.execute(insert_platform_query, {\"platform_name\": platform_name})\n",
    "        platform_result = connection.execute(platform_query, {\"platform_name\": platform_name}).fetchone()\n",
    "\n",
    "    return platform_result[0]\n",
    "\n",
    "\n",
    "def insert_post_data(connection, df, platform_id):\n",
    "    \"\"\"\n",
    "    Insert post data into Hub_Post, Sat_PostDetails, and Link_PostPlatform tables.\n",
    "    \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        # Insert into Hub_Post\n",
    "        hub_post_query = text(\"INSERT INTO Hub_Post (PlatformID, Timestamp) VALUES (:platform_id, :timestamp)\")\n",
    "        connection.execute(hub_post_query, {\"platform_id\": platform_id, \"timestamp\": row['Timestamp']})\n",
    "\n",
    "        # Get the generated PostID\n",
    "        post_id = connection.execute(text(\"SELECT LAST_INSERT_ID()\")).fetchone()[0]\n",
    "\n",
    "        # Insert into Sat_PostDetails\n",
    "        post_details_query = text(\"\"\"\n",
    "            INSERT INTO Sat_PostDetails (PostID, Username, PostContent, NumberOfLikes, NumberOfComments, NumberOfReposts, URL, SearchedTopic)\n",
    "            VALUES (:post_id, :username, :post_content, :number_of_likes, :number_of_comments, :number_of_reposts, :url, :searched_topic)\n",
    "        \"\"\")\n",
    "        connection.execute(post_details_query, {\n",
    "            \"post_id\": post_id,\n",
    "            \"username\": row['Username'],\n",
    "            \"post_content\": row['PostContent'],\n",
    "            \"number_of_likes\": row['NumberOfLikes'],\n",
    "            \"number_of_comments\": row['NumberOfComments'],\n",
    "            \"number_of_reposts\": row['NumberOfReposts'],\n",
    "            \"url\": row['URL'],\n",
    "            \"searched_topic\": row['SearchedTopic']\n",
    "        })\n",
    "\n",
    "        # Insert into Link_PostPlatform\n",
    "        link_query = text(\"INSERT INTO Link_PostPlatform (PostID, PlatformID) VALUES (:post_id, :platform_id)\")\n",
    "        connection.execute(link_query, {\"post_id\": post_id, \"platform_id\": platform_id})\n",
    "\n",
    "\n",
    "def csv_to_database(engine, csv_file_path, column_mapping):\n",
    "    \"\"\"\n",
    "    Read data from a CSV file and upload it to the database tables.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        df.columns = [column_mapping.get(col, col) for col in df.columns]\n",
    "        df = clean_and_validate_timestamps(df)\n",
    "\n",
    "        # Prompt for platform selection\n",
    "        platforms = ['reddit', 'bluesky', 'twitter', 'youtube']\n",
    "        print(\"Select the platform for this CSV file:\")\n",
    "        for i, platform in enumerate(platforms, start=1):\n",
    "            print(f\"{i}: {platform}\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                choice = int(input(\"Enter the number for the platform: \"))\n",
    "                if 1 <= choice <= len(platforms):\n",
    "                    selected_platform = platforms[choice - 1]\n",
    "                    break\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            except ValueError:\n",
    "                print(\"Invalid choice. Please enter a number from the list.\")\n",
    "\n",
    "        with engine.connect() as connection:\n",
    "            with connection.begin() as transaction:\n",
    "                platform_id = get_or_create_platform_id(connection, selected_platform)\n",
    "                insert_post_data(connection, df, platform_id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CSV file: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ssh_config = {\n",
    "        'ssh_host': '141.59.26.123',\n",
    "        'ssh_user': 'tektmu01',\n",
    "        'ssh_password': 'thu123!',\n",
    "        'remote_host': '127.0.0.1',\n",
    "        'remote_port': 3306,\n",
    "        'mysql_user': 'root',\n",
    "        'mysql_password': 'socialmedia',\n",
    "        'mysql_db': 'Predicto'\n",
    "    }\n",
    "\n",
    "    csv_file_path = 'bluesky_SearchingPosts_data_CSV (5).csv'\n",
    "    column_mapping = {\n",
    "        \"Post Number\": \"PostID\",\n",
    "        \"Topic\": \"SearchedTopic\",\n",
    "        \"URI\": \"URL\",\n",
    "        \"user\": \"Username\",\n",
    "        \"Post\": \"PostContent\",\n",
    "        \"Time\": \"Timestamp\",\n",
    "        \"Likes\": \"NumberOfLikes\",\n",
    "        \"Nb.comments\": \"NumberOfComments\",\n",
    "        \"Nb.reposts\": \"NumberOfReposts\",\n",
    "        \"Platform Name\": \"PlatformName\"\n",
    "    }\n",
    "\n",
    "    tunnel, engine = get_ssh_db_connection(ssh_config)\n",
    "\n",
    "    if engine:\n",
    "        try:\n",
    "            csv_to_database(engine, csv_file_path, column_mapping)\n",
    "        finally:\n",
    "            engine.dispose()\n",
    "\n",
    "    if tunnel:\n",
    "        tunnel.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
